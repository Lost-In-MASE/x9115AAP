### i. Paper Reviewed
Xiaoyin Wang, Lu Zhang, Tao Xie John Anvik, Jiasu Sun; "An Approach to Detecting Duplicate Bug Reports using Natural Language and Execution Information" in Software Engineering, ICSE 2008. ACM/IEEE 30th International Conference. 

###ii. Keywords and Definitions  
* **ii1. Execution Information:** Execution information or execution trace is the runtime trace generated by an instrumented version of the software to provide the bug trace report in the software code. This mainly points out the modules of codes that generated the bug. The similarity factor from this information will be more significant since this doesn't vary as much as the natural language of the text. Also the execution information provides more information about the internal abnormalities present in the software. 

* **ii2. Classification-based Heuristics:** Classification-based heuristics is used to distinguish which kind of information source, in this case natural language or execution trace, is a dormant factor. Using this heuristics the important of the two information quantities can be weighted and thus can be used to give more accurate results.  

* **ii3. Feature Request:** A feature request is a special type of the bug report that actually suggests increment to existing functionalities offered by the software. These king of bug reports don't have execution trace since such features still don't exists in the software and need to be handled seperately. Hence this type of the is discarded from the bug report category and should have a seperate category and way of dealing with dublicates. 

* **ii4. Patch Report:** These are yet another type of bug reports. These are submitted by a highly technical bug reporter that directly points to a bug in the code with a suggestion of fixes. These bugs also do not have execution trace. These are typically rare and its highly unlikely that two experts find the same bug in the code at the same time and report it simultaneously. These also normally easy to fix and thus are ignored in the analysis. 

### iii. Brief notes 

#####iii1. Motivation
Many a times multiple bugs have the same natural language and many times multiple bugs have similar execution trace with slightly different endings due to difference in some condition. Thus both these informations independently cannot determine the similarities in the bugs. Examples of these are given in the paper from the Firefox bug repository. The natural language normally represents the external appearance of the bug while the execution information normally represents the internal abnormalities in the software. Thus, combining the internal and external parameters might lead to better results. This was the key motivating factor behind combining the two approaches. 

#####iii2. Hypotheses

#####iii3. Data
The data used to collect bug reports were used from the Eclipse bug repository and Firefox bug repository. The eclipse bug repository was used to calibrate the paramters of the approach and then the firefox bug repository was used to evaluate the approach. Some of the special bug reports like feature request and the patch reports were ignored. 

#####iii4. Visualization

### iv. Improvements  
* iv1. The execution trace though adds a lot to the accuracy of bug detection, execution trace also adds added cost on the bug reporters. Bug reporters have to run the instrumented version of the software to re-generate the bugs and publish the execution trace. This can be cumbersome for the reports and time consuming as well. This can be improved in future works by adding automated ways of publishing this execution trace.  

* iv2. The execution trace should also be stored in the bug repository, increasing the size of the repository by manifold. A typical eclipse bug report has around 30,000 modules and hence the trace can be as big as 1MB per bug. Thus additional space in GB's is required to store the execution trace. This effectively also increases the cost of computing the similarity score for execution trace with such a large size. Thus, the algorithm for finding the similarity and conservatively storing this execution trace should be the starting point of improving this algorithm. 

* iv3. Finally, the current paper used Eclipse bug repository to calibrate the model parameters of their approach and then used the firefox repository to evaluate the model containing only 1492 bug reports. First the evaluation techniques are not precise and they should use a better evaluating technique and also the model needs to be evaluated on wider range of projects and on a larger scale of bug reports. This will provide a better and more significant results. 

### v. Connection to the Initial Paper
The previously reviewed paper [1] took inspiration from this paper to consider other features available in bug reports like product component, product version and product priority in addition to the text present in the bug report. The previously reviewed paper is not able to use the execution trace since in general not all bug repositories have execution trace and hence such method cannot be generalized. But having said that the reviewed paper does appreciates the value of additional execution details available in the report which is generally unambiguous as compared to varying natural languge text present in the report. 

### vi. References
* [1] C. Sun, D. Lo, S.-C. Khoo, and J. Jiang, “Towards more accurate retrieval of duplicate bug reports,” in Proceedings of the IEEE/ACM International Conference on Automated Software Engineering, 2011.